{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Encoding de Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as 5 técnicas abaixo conseguimos lidar com a grande maioria das necessidades de conversão de veriáveis categóricas em numéricas. São eles:\n",
    "\n",
    "- One Hot Encoding;\n",
    "- Count/Frequency\n",
    "- Target Encoding (\"Model\" encoding);\n",
    "- Embedding;\n",
    "- Ordinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import median_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data-processed/train.csv\")\n",
    "val = pd.read_csv(\"data-processed/val.csv\")\n",
    "\n",
    "train['DATE_TIME'] = pd.to_datetime(train['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "val['DATE_TIME'] = pd.to_datetime(val['DATE_TIME'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "train2['WEEKDAY'] = train2['DATE_TIME'].dt.weekday\n",
    "train2['HOUR'] = train2['DATE_TIME'].dt.hour\n",
    "train2['MINUTE'] = train2['DATE_TIME'].dt.minute\n",
    "\n",
    "val2 = val.copy()\n",
    "val2['WEEKDAY'] = val2['DATE_TIME'].dt.weekday\n",
    "val2['HOUR'] = val2['DATE_TIME'].dt.hour\n",
    "val2['MINUTE'] = val2['DATE_TIME'].dt.minute\n",
    "cats = ['SOURCE_KEY', 'WEEKDAY','HOUR', 'MINUTE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count/Frequency Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz um proporcional entre a quantidade de vezes que um tipo de valor aparece sobre o total de valores disponíveis.\n",
    "\n",
    "Funciona muito bem quando temos muitos valores diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import CountEncoder\n",
    "\n",
    "for c in cats:\n",
    "    cenc = CountEncoder(normalize=False)\n",
    "    train2['COUNT_{}'.format(c)] = cenc.fit_transform(train2[c])\n",
    "    val2['COUNT_{}'.format(c)] = cenc.transform(val2[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.598091929386687"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2.filter(regex=r\"COUNT\"), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2.filter(regex=r\"COUNT\"))\n",
    "\n",
    "# Faz a validação contra o Y4 normal por não sabemos o valor Y4WIN na produção\n",
    "# então não adianta ficar tratando ele aqui\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grande risco de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "for c in cats:\n",
    "    tenc = TargetEncoder()\n",
    "    train2['TGT_{}'.format(c)] = tenc.fit_transform(train2[c], train2['Y4WIN'])\n",
    "    val2['TGT_{}'.format(c)] = tenc.transform(val2[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6372917733329757"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2.filter(regex=r\"TGT\"), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2.filter(regex=r\"TGT\"))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPIDS Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2fe2412f1a2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtenc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TGT_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtenc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y4WIN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "from cuml.preprocessing import TargetEncoder\n",
    "\n",
    "for c in cats:\n",
    "    tenc = TargetEncoder(n_folds=2)\n",
    "    train2['TGT_{}'.format(c)] = tenc.fit_transform(train2[c], train2['Y4WIN'])\n",
    "    val2['TGT_{}'.format(c)] = tenc.transform(val2[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2.filter(regex=r\"TGT\"), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2.filter(regex=r\"TGT\"))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPIDS KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import KNeighborsRegressor\n",
    "\n",
    "mdl = KNeighborsRegressor(n_neighbors=1, metric='manhattan')\n",
    "\n",
    "Xtr, ytr = train2.filter(regex=r\"TGT\"), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2.filter(regex=r\"TGT\"))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPIDS OHE + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import OneHotEncoder\n",
    "import cudf\n",
    "import cupy\n",
    "\n",
    "cudf_train2 = cudf.from_pandas(train2[cats])\n",
    "cudf_val2 = cudf.from_pandas(val2[cats])\n",
    "\n",
    "ohenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "cudf_train2 = ohenc.fit_transform(cudf_train2)\n",
    "cudf_val2 = ohenc.transform(cudf_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import KNeighborsRegressor\n",
    "mdl = KNeighborsRegressor(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "Xtr, ytr = cudf_train2, train2['Y4WIN']\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(cudf_val2)\n",
    "p = cupy.asnumpy(p)\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ótima forma de reduzir esparsidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "cats = ['SOURCE_KEY', 'WEEKDAY','HOUR', 'MINUTE']\n",
    "\n",
    "new_features = set()\n",
    "new_features_models = list()\n",
    "for c in cats:\n",
    "    \n",
    "    mdl = make_pipeline(OneHotEncoder(cols=[c]), Ridge())\n",
    "    mdl.fit(train2[[c]], train2['Y4WIN'])\n",
    "    feature = mdl.predict(train2[[c]])\n",
    "    \n",
    "    train2[\"P_{}\".format(c)] = mdl.predict(train2[[c]])\n",
    "    val2[\"P_{}\".format(c)] = mdl.predict(val2[[c]])\n",
    "    \n",
    "    new_features.add(\"P_{}\".format(c))\n",
    "    \n",
    "    #new_features_models.append(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1369276674286795"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(new_features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2[features].fillna(-1), train2['Y4']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2[features].fillna(-1))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução da Cardinalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bvBOhCH3iADSZry    1526\n",
       "1BY6WEcLGh8j5v7    1525\n",
       "VHMLBKoKgIrUVDU    1511\n",
       "7JYdWkrLSPkdwr4    1511\n",
       "ih0vzX44oOqAx2f    1508\n",
       "ZnxXDlPa8U1GXgE    1508\n",
       "z9Y9gH1T5YWrNuG    1506\n",
       "pkci93gMrogZuBj    1506\n",
       "iCRJl6heRkivqQ3    1506\n",
       "uHbuxQJl8lW7ozc    1506\n",
       "wCURE6d3bPkepu2    1506\n",
       "McdE0feGgRqW7Ca    1505\n",
       "sjndEbLyjtCKgGv    1505\n",
       "zVJPv84UY57bAof    1505\n",
       "rGa61gmuvPhdLxV    1505\n",
       "ZoEaEvLYb1n2sOq    1504\n",
       "zBIq5rxdHJRwDNY    1500\n",
       "adLQvlD726eNBSB    1496\n",
       "WRmjgnKYAwPKWDb    1496\n",
       "1IF53ai7Xc0U56Y    1496\n",
       "3PZuoBAID5Wc2HD    1496\n",
       "YxYtjZvoooNbGkE    1485\n",
       "Name: SOURCE_KEY, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_counts = train['SOURCE_KEY'].value_counts()\n",
    "level_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1IF53ai7Xc0U56Y',\n",
       " '3PZuoBAID5Wc2HD',\n",
       " 'WRmjgnKYAwPKWDb',\n",
       " 'YxYtjZvoooNbGkE',\n",
       " 'adLQvlD726eNBSB'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_count = set(level_counts[level_counts < 1500].index)\n",
    "low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "cats = ['SOURCE_KEY', 'WEEKDAY','HOUR', 'MINUTE']\n",
    "\n",
    "new_features = set()\n",
    "new_features_models = list()\n",
    "for c in cats:\n",
    "    \n",
    "    mdl = make_pipeline(OneHotEncoder(cols=[c]), Ridge())\n",
    "    mdl.fit(train2[[c]], train2['Y4WIN'])\n",
    "    feature = mdl.predict(train2[[c]])\n",
    "    \n",
    "    train2[\"P_{}\".format(c)] = mdl.predict(train2[[c]])\n",
    "    val2[\"P_{}\".format(c)] = mdl.predict(val2[[c]])\n",
    "    \n",
    "    new_features.add(\"P_{}\".format(c))\n",
    "    \n",
    "    #new_features_models.append(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6099226169563714"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(new_features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2[features].fillna(-1), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2[features].fillna(-1))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA e Derivados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma combinação legal é fazer One Hot Encoding e depois aplicar PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "R:\\Install\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cats = ['SOURCE_KEY', 'WEEKDAY','HOUR', 'MINUTE']\n",
    "\n",
    "new_features = set()\n",
    "new_features_models = list()\n",
    "for c in cats:\n",
    "    \n",
    "    mdl = make_pipeline(OneHotEncoder(cols=[c]), PCA(n_components=1))\n",
    "    mdl.fit(train2[[c]])\n",
    "    feature = mdl.transform(train2[[c]])\n",
    "    \n",
    "    train2[\"P_{}\".format(c)] = mdl.transform(train2[[c]])\n",
    "    val2[\"P_{}\".format(c)] = mdl.transform(val2[[c]])\n",
    "    \n",
    "    new_features.add(\"P_{}\".format(c))\n",
    "    \n",
    "    #new_features_models.append(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6454963788213064"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(new_features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mdl = RandomForestRegressor(n_jobs=-1, random_state=0, n_estimators=100)\n",
    "\n",
    "Xtr, ytr = train2[features].fillna(-1), train2['Y4WIN']\n",
    "\n",
    "mdl.fit(Xtr,ytr)\n",
    "\n",
    "p = mdl.predict(val2[features].fillna(-1))\n",
    "\n",
    "median_absolute_error(val2['Y4'], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
